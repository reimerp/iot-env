# Read metrics about cpu usage
[[inputs.cpu]]
  ## Whether to report per-cpu stats or not
  percpu = false
  ## Whether to report total system cpu stats or not
  totalcpu = true
  ## If true, collect raw CPU time metrics
  collect_cpu_time = false
  ## If true, compute and report the sum of all non-idle CPU states
  ## NOTE: The resulting 'time_active' field INCLUDES 'iowait'!
  report_active = false
  ## If true and the info is available then add core_id and physical_id tags
  core_tags = false


# Read metrics about disk usage by mount point
# TODO what is /tmp/crun... ?, inodes are 0 on btrfs
[[inputs.disk]]
  ## By default stats will be gathered for all mount points.
  ## Set mount_points will restrict the stats to only the specified mount points.
  # mount_points = ["/", "/boot"]
  #mount_points = ["/", "/boot/firmware"]

  ## Ignore mount points by filesystem type.
  ignore_fs = ["tmpfs", "devtmpfs", "devfs", "iso9660", "overlay", "aufs", "squashfs", "nsfs", "tracefs", "binfmt_misc", "configfs", "mqueue", "pstore", "efivarfs"]

  ## Ignore mount points by mount options.
  ## The 'mount' command reports options of all mounts in parathesis.
  ## Bind mounts can be ignored with the special 'bind' option.
  # ignore_mount_opts = []


# Read metrics about disk IO by device
[[inputs.diskio]]
  ## Devices to collect stats for
  ## Wildcards are supported except for disk synonyms like '/dev/disk/by-id'.
  ## ex. devices = ["sda", "sdb", "vd*", "/dev/disk/by-id/nvme-eui.00123deadc0de123"]
  # devices = ["*"]
  devices = ["sd*", "nvme*"]

  ## Skip gathering of the disk's serial numbers.
  # skip_serial_number = true

  ## Device metadata tags to add on systems supporting it (Linux only)
  ## Use 'udevadm info -q property -n <device>' to get a list of properties.
  ## Note: Most, but not all, udev properties can be accessed this way. Properties
  ## that are currently inaccessible include DEVTYPE, DEVNAME, and DEVPATH.
  # device_tags = ["ID_FS_TYPE", "ID_FS_USAGE"]

  ## Using the same metadata source as device_tags, you can also customize the
  ## name of the device via templates.
  ## The 'name_templates' parameter is a list of templates to try and apply to
  ## the device. The template may contain variables in the form of '$PROPERTY' or
  ## '${PROPERTY}'. The first template which does not contain any variables not
  ## present for the device is used as the device name tag.
  ## The typical use case is for LVM volumes, to get the VG/LV name instead of
  ## the near-meaningless DM-0 name.
  # name_templates = ["$ID_FS_LABEL","$DM_VG_NAME/$DM_LV_NAME"]


# Plugin to collect various Linux kernel statistics. (/proc/stat, includes boot_time)
# This plugin ONLY supports Linux
[[inputs.kernel]]
  ## Additional gather options
  ## Possible options include:
  ## * ksm - kernel same-page merging
  ## * psi - pressure stall information
  # collect = []


# Read metrics about memory usage
[[inputs.mem]]
  # no configuration


# Get the number of processes and group them by status
# This plugin ONLY supports non-Windows
[[inputs.processes]]
  ## Use sudo to run ps command on *BSD systems. Linux systems will read
  ## /proc, so this does not apply there.
  use_sudo = false


# Read metrics about swap memory usage
[[inputs.swap]]
  # no configuration


# Read metrics about system load & uptime
# TODO uptime_format="7 days, 15:40"
[[inputs.system]]
  # no configuration


# Collects conntrack stats from the configured directories and files.
# This plugin ONLY supports Linux
[[inputs.conntrack]]
  ## The following defaults would work with multiple versions of conntrack.
  ## Note the nf_ and ip_ filename prefixes are mutually exclusive across
  ## kernel versions, as are the directory locations.

  ## Look through /proc/net/stat/nf_conntrack for these metrics
  ## all - aggregated statistics
  ## percpu - include detailed statistics with cpu tag
  #collect = ["all", "percpu"]

  ## Superset of filenames to look for within the conntrack dirs.
  ## Missing files will be ignored.
  files = ["ip_conntrack_count","ip_conntrack_max",
          "nf_conntrack_count","nf_conntrack_max"]

  ## User-specified directories and files to look through
  ## Directories to search within for the conntrack files above.
  ## Missing directories will be ignored.
  dirs = ["/proc/sys/net/ipv4/netfilter","/proc/sys/net/netfilter"]


# # Returns ethtool statistics for given interfaces
# # This plugin ONLY supports Linux
# [[inputs.ethtool]]


# Monitor disks' temperatures using hddtemp
# [[inputs.hddtemp]]
# braucht hddtemp daemon 127.0.0.1:7634


# # Collect statistics about itself
[[inputs.internal]]
  ## If true, collect telegraf memory stats.
  # collect_memstats = true

  ## If true, collect metrics from Go's runtime.metrics. For a full list see:
  ##   https://pkg.go.dev/runtime/metrics
  # collect_gostats = false

  ## Collect statistics per plugin instance and not per plugin type
  # per_instance = false


# # This plugin gathers interrupts data from /proc/interrupts and /proc/softirqs.
[[inputs.interrupts]]
  ## When set to true, cpu metrics are tagged with the cpu.  Otherwise cpu is
  ## stored as a field.
  ##
  ## The default is false for backwards compatibility, and will be changed to
  ## true in a future version.  It is recommended to set to true on new
  ## deployments.
  cpu_as_tag = true

  ## To filter which IRQs to collect, make use of tagpass / tagdrop:
  # [inputs.interrupts.tagdrop]
  #   irq = [ "NET_RX", "TASKLET" ]


# # Get kernel statistics from /proc/vmstat
# # This plugin ONLY supports Linux
[[inputs.kernel_vmstat]]
  # no configuration


# # Provides Linux CPU metrics
# # This plugin ONLY supports Linux
[[inputs.linux_cpu]]
  ## Path for sysfs filesystem.
  ## See https://www.kernel.org/doc/Documentation/filesystems/sysfs.txt
  ## Defaults:
  host_sys = "${HOST_SYS}"

  ## CPU metrics collected by the plugin.
  ## Supported options:
  ## "cpufreq", "thermal"
  ## Defaults:
  # metrics = ["cpufreq"]


# # Provides Linux sysctl fs metrics
[[inputs.linux_sysctl_fs]]
#   # no configuration


# # Get kernel statistics from /proc/mdstat
# # This plugin ONLY supports Linux
# [[inputs.mdstat]]
#   ## Sets file path
#   ## If not specified, then default is /proc/mdstat
#   # file_name = "/proc/mdstat"


# # Gather metrics about network interfaces
[[inputs.net]]
  ## By default, telegraf gathers stats from any up interface (excluding loopback)
  ## Setting interfaces will tell it to gather these explicit interfaces,
  ## regardless of status. When specifying an interface, glob-style
  ## patterns are also supported.
  # interfaces = ["eth*", "enp0s[0-1]", "lo"]


# # Read TCP metrics such as established, time wait and sockets counts.
[[inputs.netstat]]
  # no configuration


# # Collect kernel snmp counters and network interface statistics
# [[inputs.nstat]]
#   ## file paths for proc files. If empty default paths will be used:
#   ##    /proc/net/netstat, /proc/net/snmp, /proc/net/snmp6
#   ## These can also be overridden with env variables, see README.
#   proc_net_netstat = "${HOST_PROC}/net/netstat"
#   proc_net_snmp = "${HOST_PROC}/net/snmp"
#   proc_net_snmp6 = "${HOST_PROC}/net/snmp6"
#   ## dump metrics with 0 values too
#   dump_zeros       = false


# # Monitor sensors, requires lm-sensors package
# # This plugin ONLY supports Linux
[[inputs.sensors]]
  ## Remove numbers from field names.
  ## If true, a field name like 'temp1_input' will be changed to 'temp_input'.
  # remove_numbers = true

  ## Timeout is the maximum amount of time that the sensors command can run.
  # timeout = "5s"
  [[processors.rename]]
    namepass = ["sensors"]
    [[processors.rename.replace]]
      field = "temp_input"
      dest = "Temperature"


# # Read metrics about temperature
[[inputs.temp]]
  ## Desired output format (Linux only)
  ## Available values are
  ##   v1 -- use pre-v1.22.4 sensor naming, e.g. coretemp_core0_input
  ##   v2 -- use v1.22.4+ sensor naming, e.g. coretemp_core_0_input
  # metric_format = "v2"

  ## Add device tag to distinguish devices with the same name (Linux only)
  # add_device_tag = false


# # Read time metrics from linux timex interface.
# R: not on DT
[[inputs.timex]]
  ## No input configuration


#[[inputs.wireless]]
#  host_proc = "${HOST_PROC}"


# Read metrics about docker containers
[[inputs.docker]]
  ## Docker Endpoint
  ##   To use TCP, set endpoint = "tcp://[ip]:[port]"
  ##   To use environment variables (ie, docker-machine), set endpoint = "ENV"
  # endpoint = "unix:///var/run/docker.sock"

  ## Set to true to collect Swarm metrics(desired_replicas, running_replicas)
  ## Note: configure this in one of the manager nodes in a Swarm cluster.
  ## configuring in multiple Swarm managers results in duplication of metrics.
  #gather_services = false

  ## Set the source tag for the metrics to the container ID hostname, eg first 12 chars
  source_tag = false

  ## Containers to include and exclude. Collect all if empty. Globs accepted.
  container_name_include = []
  container_name_exclude = []

  ## Container states to include and exclude. Globs accepted.
  ## When empty only containers in the "running" state will be captured.
  ## example: container_state_include = ["created", "restarting", "running", "removing", "paused", "exited", "dead"]
  ## example: container_state_exclude = ["created", "restarting", "running", "removing", "paused", "exited", "dead"]
  # container_state_include = []
  # container_state_exclude = []

  ## Objects to include for disk usage query
  ## Allowed values are "container", "image", "volume"
  ## When empty disk usage is excluded
  storage_objects = []

  ## Timeout for docker list, info, and stats commands
  timeout = "5s"

  ## Podman compatibility settings (auto-enabled when Podman detected)
  ## Cache TTL for accurate CPU percentage calculation (default: 60s)
  ## Set higher than your collection interval for accurate measurements
  ## Set to 0 to keep cache entries forever (not recommended for dynamic environments)
  # podman_cache_ttl = "60s"

  ## Specifies for which classes a per-device metric should be issued
  ## Possible values are 'cpu' (cpu0, cpu1, ...), 'blkio' (8:0, 8:1, ...) and 'network' (eth0, eth1, ...)
  # perdevice_include = ["cpu"]

  ## Specifies for which classes a total metric should be issued. Total is an aggregated of the 'perdevice_include' values.
  ## Possible values are 'cpu', 'blkio' and 'network'
  ## Total 'cpu' is reported directly by Docker daemon, and 'network' and 'blkio' totals are aggregated by this plugin.
  # total_include = ["cpu", "blkio", "network"]

  ## docker labels to include and exclude as tags.  Globs accepted.
  ## Note that an empty array for both will include all labels as tags
  docker_label_include = []
  docker_label_exclude = []

  ## Which environment variables should we use as a tag
  tag_env = ["JAVA_HOME", "HEAP_SIZE"]

  ## Optional TLS Config
  # tls_ca = "/etc/telegraf/ca.pem"
  # tls_cert = "/etc/telegraf/cert.pem"
  # tls_key = "/etc/telegraf/key.pem"
  ## Use TLS but skip chain & host verification
  # insecure_skip_verify = false


# Statsd Server
# [[inputs.statsd]]
#   ## Protocol, must be "tcp", "udp4", "udp6" or "udp" (default=udp)
#   protocol = "udp"

#   ## MaxTCPConnection - applicable when protocol is set to tcp (default=250)
#   max_tcp_connections = 250

#   ## Enable TCP keep alive probes (default=false)
#   tcp_keep_alive = false

#   ## Specifies the keep-alive period for an active network connection.
#   ## Only applies to TCP sockets and will be ignored if tcp_keep_alive is false.
#   ## Defaults to the OS configuration.
#   # tcp_keep_alive_period = "2h"

#   ## Address and port to host UDP listener on
#   service_address = ":8125"

#   ## The following configuration options control when telegraf clears it's cache
#   ## of previous values. If set to false, then telegraf will only clear it's
#   ## cache when the daemon is restarted.
#   ## Reset gauges every interval (default=true)
#   delete_gauges = true
#   ## Reset counters every interval (default=true)
#   delete_counters = true
#   ## Reset sets every interval (default=true)
#   delete_sets = true
#   ## Reset timings & histograms every interval (default=true)
#   delete_timings = true

#   ## Percentiles to calculate for timing & histogram stats
#   # percentiles = [50.0, 90.0, 99.0, 99.9, 99.95, 100.0]
#   percentiles = [90]

#   ## separator to use between elements of a statsd metric
#   metric_separator = "_"

#   ## Parses tags in the datadog statsd format
#   ## http://docs.datadoghq.com/guides/dogstatsd/
#   parse_data_dog_tags = false

#   ## Parses datadog extensions to the statsd format
#   datadog_extensions = false

#   ## Statsd data translation templates, more info can be read here:
#   ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md#graphite
#   # templates = [
#   #     "cpu.* measurement*"
#   # ]

#   ## Number of UDP messages allowed to queue up, once filled,
#   ## the statsd server will start dropping packets
#   allowed_pending_messages = 10000

#   ## Number of timing/histogram values to track per-measurement in the
#   ## calculation of percentiles. Raising this limit increases the accuracy
#   ## of percentiles but also increases the memory usage and cpu time.
#   percentile_limit = 1000

#   ## Maximum socket buffer size in bytes, once the buffer fills up, metrics
#   ## will start dropping.  Defaults to the OS default.
#   # read_buffer_size = 65535
